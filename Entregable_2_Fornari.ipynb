{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "tvwd0cQcqA_v"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "from psycopg2.extras import execute_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcfAq4UIs5H8",
        "outputId": "71cf743e-d036-4dbf-bfbd-4ba530117f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "ROOT_DIR = \"/content/drive/\"\n",
        "drive.mount(ROOT_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Mb8cE_6_rvL8"
      },
      "outputs": [],
      "source": [
        "PROJECT_DIR = os.path.join(ROOT_DIR,\"MyDrive\", \"DE\",\"CHPF\")\n",
        "os.chdir(PROJECT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "HubFvvpwhwUQ"
      },
      "outputs": [],
      "source": [
        "with open(\"api_token.txt\",'r') as f:\n",
        "  api_token = f.read()\n",
        "\n",
        "api_urls_to_query = dict(\n",
        "  milestones = \"https://api.estadisticasbcra.com/milestones\",\n",
        "  blue_usd = \"https://api.estadisticasbcra.com/usd\",\n",
        "  official_usd = \"https://api.estadisticasbcra.com/usd_of\"\n",
        "  )\n",
        "retrieved_tables = dict()\n",
        "headers = {\"Authorization\": f\"Bearer {api_token}\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_zyjmpSpsQI",
        "outputId": "daa5bb76-9ab2-47ea-de0c-850a06be910a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  4.21it/s]\n"
          ]
        }
      ],
      "source": [
        "for tablename, api_url in tqdm(api_urls_to_query.items()):\n",
        "  result = requests.get(api_url, headers=headers)\n",
        "  result_json = result.json()\n",
        "  df = pd.DataFrame( result_json ).rename(columns={\"d\":\"date\",\"e\":\"event\",\"v\":\"value\",\"t\":\"event_type\"})\n",
        "  df[\"date\"] = pd.to_datetime(df[\"date\"], format='%Y-%m-%d')\n",
        "  retrieved_tables[tablename] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQXZJPJWkxA0",
        "outputId": "4e3952fa-8271-4435-c653-dafffdccbc9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['milestones', 'blue_usd', 'official_usd'])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_tables.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El-YWLu333pK",
        "outputId": "ba969a11-950b-43d3-cf5f-bedc7870e9a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       2002-03-04\n",
              "1       2002-03-05\n",
              "2       2002-03-06\n",
              "3       2002-03-07\n",
              "4       2002-03-08\n",
              "           ...    \n",
              "5302    2023-10-05\n",
              "5303    2023-10-06\n",
              "5304    2023-10-09\n",
              "5305    2023-10-10\n",
              "5306    2023-10-11\n",
              "Name: date, Length: 5307, dtype: object"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_tables[\"official_usd\"][\"date\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "VOad6tPKsoyP"
      },
      "outputs": [],
      "source": [
        "with open(\"redshift_credentials.json\",'r') as f:\n",
        "   redshift_credentials = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "UFcljN5SR6AI"
      },
      "outputs": [],
      "source": [
        "schema_name = \"javier_coderhouse\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "bE3ZnjZqzpCG"
      },
      "outputs": [],
      "source": [
        "def create_table(table_name: str, schema_name: str, dataframe: pd.DataFrame, primary_key: str = None, foreign_keys: dict = None, diststyle: str = \"EVEN\", distkey: str = \"\", sortkeys: list = None) -> str:\n",
        "    \"\"\"\n",
        "    Generates SQL schema for creating a table in the specified schema based on the given dataframe's structure,\n",
        "    including primary key and foreign key constraints if specified, and with considerations for DISTSTYLE and SORTKEY\n",
        "    for performance optimization in Redshift.\n",
        "\n",
        "    Parameters:\n",
        "    - table_name (str): Name of the SQL table to be created.\n",
        "    - schema_name (str): Name of the SQL schema where the table will be created.\n",
        "    - dataframe (pd.DataFrame): DataFrame whose structure will be used to define the table schema.\n",
        "    - primary_key (str): Column name to be set as primary key. Optional.\n",
        "    - foreign_keys (dict): A dictionary where keys are column names that should be foreign keys, \n",
        "                           and values are tuples containing the reference table and reference column, respectively. Optional.\n",
        "    - diststyle (str): Distribution style of the table (EVEN, KEY, ALL).\n",
        "    - distkey (str): Column name to be used as the DISTKEY for KEY distribution style.\n",
        "    - sortkeys (list): A list of column names to be used as the SORTKEY. Use a single element list for a single sort key,\n",
        "                       or a multiple element list for compound sort keys.\n",
        "    \n",
        "    Returns:\n",
        "    - str: SQL query string to create the table within the specified schema with the appropriate columns, \n",
        "           data types, and constraints, including DISTSTYLE and SORTKEY configurations.\n",
        "    Note:\n",
        "    This function supports the following data types mapping:\n",
        "    int64 -> INT\n",
        "    int32 -> INT\n",
        "    float64 -> FLOAT\n",
        "    object -> VARCHAR(300)\n",
        "    bool -> BOOLEAN\n",
        "    datetime64[ns] -> DATE\n",
        "    \"\"\"\n",
        "    type_map = {'int64': 'INT', 'int32': 'INT', 'float64': 'FLOAT',\n",
        "                'object': 'VARCHAR(300)', 'bool': 'BOOLEAN', 'datetime64[ns]': 'TIMESTAMP'} \n",
        "    column_defs = [f\"{col} {type_map[str(dtype)]}\" for col, dtype in dataframe.dtypes.items()]\n",
        "    \n",
        "    if primary_key:\n",
        "        column_defs.append(f\"PRIMARY KEY ({primary_key})\")\n",
        "    \n",
        "    if foreign_keys:\n",
        "        for column, (reference_table, reference_column) in foreign_keys.items():\n",
        "            column_defs.append(f\"FOREIGN KEY ({column}) REFERENCES {reference_table}({reference_column})\")\n",
        "    \n",
        "    dist_clause = f\"DISTSTYLE {diststyle}\"\n",
        "    if diststyle.upper() == \"KEY\" and distkey:\n",
        "        dist_clause += f\" DISTKEY({distkey})\"\n",
        "    \n",
        "    sort_clause = \"\"\n",
        "    if sortkeys:\n",
        "        if len(sortkeys) > 1:\n",
        "            sort_clause = f\"SORTKEY({', '.join(sortkeys)})\"\n",
        "        else:\n",
        "            sort_clause = f\"SORTKEY({sortkeys[0]})\"\n",
        "    \n",
        "    table_schema = f\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS {schema_name}.{table_name} (\n",
        "            {', '.join(column_defs)}\n",
        "        )\n",
        "        {dist_clause}\n",
        "        {sort_clause};\n",
        "    \"\"\"\n",
        "    return table_schema\n",
        "\n",
        "def prepare_insert_values(table_name: str, schema_name: str, dataframe: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Generates SQL insert statements for the given dataframe's rows into the specified table within a given schema in Redshift.\n",
        "    \n",
        "    Parameters:\n",
        "    - table_name (str): Name of the SQL table to insert the values.\n",
        "    - schema_name (str): Name of the SQL schema where the table resides.\n",
        "    - dataframe (pd.DataFrame): DataFrame whose values will be prepared for insertion.\n",
        "    \n",
        "    Returns:\n",
        "    - str: SQL query string to insert the dataframe's rows into the specified table within the given schema.\n",
        "    \n",
        "    Note:\n",
        "    This function converts the 'date' column of the dataframe to string in the format compatible with Redshift before insertion.\n",
        "    \"\"\"\n",
        "    # Ensure that 'date' columns in the dataframe are converted to a string format compatible with Redshift\n",
        "    for col, dtype in dataframe.dtypes.items():\n",
        "        if \"datetime64[ns]\" in str(dtype):\n",
        "            dataframe[col] = dataframe[col].dt.strftime('%Y-%m-%d %H:%M:%S')  # Assuming you want to keep time information\n",
        "\n",
        "    cols = dataframe.columns.tolist()\n",
        "    values_str_list = []\n",
        "    for _, row in dataframe.iterrows():\n",
        "        row_values = ', '.join([f\"'{str(item).replace(\"'\", \"''\")}'\" if isinstance(item, str) else (str(item) if not pd.isnull(item) else 'NULL') for item in row])\n",
        "        values_str_list.append(f\"({row_values})\")\n",
        "\n",
        "    values_str = \",\\n\".join(values_str_list)\n",
        "    insert_sql = f\"INSERT INTO {schema_name}.{table_name} ({', '.join(cols)}) VALUES {values_str};\"\n",
        "    \n",
        "    return insert_sql\n",
        "\n",
        "def query_to_df(query):\n",
        "    \"\"\"\n",
        "    Executes a SQL query using a predefined connection to a Redshift database and returns the result as a pandas DataFrame.\n",
        "    \n",
        "    Parameters:\n",
        "    - query (str): SQL query string to be executed.\n",
        "    \n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame representation of the SQL query results.\n",
        "    \n",
        "    Note:\n",
        "    This function utilizes global Redshift credentials for establishing a connection.\n",
        "    Ensure that 'redshift_credentials' is properly defined and accessible before invoking this function.\n",
        "    \"\"\"\n",
        "    conn = psycopg2.connect(**redshift_credentials)\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(query)\n",
        "    retrieved_query = cur.fetchall()\n",
        "    colnames = [x.name for x in cur.description]\n",
        "    df_query = pd.DataFrame(retrieved_query , columns = colnames)\n",
        "    cur.close()\n",
        "    conn.close()\n",
        "    return df_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "rhC_lQSRsB_K"
      },
      "outputs": [],
      "source": [
        "for table_name, dataframe in retrieved_tables.items():\n",
        "  conn = psycopg2.connect(**redshift_credentials)\n",
        "  table_schema = create_table(table_name=table_name,schema_name=schema_name, dataframe=dataframe, primary_key='date', foreign_keys= None, diststyle='EVEN', sortkey='sort_column')\n",
        "  cur = conn.cursor()\n",
        "  cur.execute(\"BEGIN\")\n",
        "  cur.execute(table_schema)\n",
        "  insert_sql = prepare_insert_values(table_name=table_name, schema_name=schema_name,dataframe=dataframe)\n",
        "  cur.execute(insert_sql)\n",
        "  cur.execute(\"COMMIT\")\n",
        "  cur.close()\n",
        "  conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nKBRXM2uIc6",
        "outputId": "dda7b287-aa11-4923-e389-a2e1bf390c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving data (first 5 rows) from table: milestones\n",
            "==============================\n",
            "         date              event event_type\n",
            "0  1991-02-05    Roque Fernández       bcra\n",
            "1  1991-04-01    Domingo Cavallo       econ\n",
            "2  1995-08-08  Carlos Saúl Menem       pres\n",
            "3  1996-08-05          Pedro Pou       bcra\n",
            "4  1996-08-06    Roque Fernández       econ\n",
            "Retrieving data (first 5 rows) from table: blue_usd\n",
            "==============================\n",
            "         date   value\n",
            "0  2000-05-24  1.0005\n",
            "1  2000-05-25  1.0005\n",
            "2  2000-05-26  1.0004\n",
            "3  2000-05-29  1.0007\n",
            "4  2000-05-30  1.0009\n",
            "Retrieving data (first 5 rows) from table: official_usd\n",
            "==============================\n",
            "         date  value\n",
            "0  2002-03-04   2.01\n",
            "1  2002-03-05   1.99\n",
            "2  2002-03-06   2.05\n",
            "3  2002-03-07   2.14\n",
            "4  2002-03-08   2.20\n"
          ]
        }
      ],
      "source": [
        "for table_name in retrieved_tables.keys():\n",
        "  print(f\"Retrieving data (first 5 rows) from table: {table_name}\")\n",
        "  example = query_to_df( f\"SELECT * FROM {schema_name}.{table_name} LIMIT 5\")\n",
        "  print(\"=\"*30)\n",
        "  print(example)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
